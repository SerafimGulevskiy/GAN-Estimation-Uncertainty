{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988da44f-1c41-4a11-94f2-1b5fe24e2e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9ecab3-c16a-407d-924a-922a791c73ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, OneCycleLR\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913af23e-f22e-4255-bdfc-5a1211dc1c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6087d6-0ca6-4476-bc3f-1c4dccbf3a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "])\n",
    "class MNISTWithAugmentation(torch.utils.data.Dataset):\n",
    "    def __init__(self,\n",
    "                 root = './data',\n",
    "                 train = True, \n",
    "                 transform = None,\n",
    "                 download = True):\n",
    "        \n",
    "        self.mnist = MNIST(root=root,\n",
    "                           train=train,\n",
    "                           transform=None,\n",
    "                           download=download)\n",
    "        \n",
    "        self.base_transform = transforms.Compose([\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "                            ])\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mnist)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image, label = self.mnist[index]\n",
    "        image = self.base_transform(image)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754b5626-0200-47a3-882f-9b2723a66a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image processing\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "])\n",
    "\n",
    "# # MNIST dataset\n",
    "# train_dataset = MNIST(root='./data', \n",
    "#                       train=True, \n",
    "#                       transform=transform,\n",
    "#                       download=True)\n",
    "\n",
    "train_dataset = MNISTWithAugmentation(root = './data', \n",
    "                                  train = True, \n",
    "                                  transform = transforms.Compose([\n",
    "        transforms.RandomAffine(degrees = 20, translate = (0.1,0.1), scale = (0.9, 1.1))\n",
    "    ]),\n",
    "                                  download = True)\n",
    "\n",
    "\n",
    "test_dataset = MNIST(root='./data', \n",
    "                     train=False, \n",
    "                     transform=transform,\n",
    "                     download=True)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=BATCH_SIZE, \n",
    "                          shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=BATCH_SIZE, \n",
    "                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f233bd7b-0169-4bee-a8c2-73b8b21f1daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denorm(x):\n",
    "    out = (x + 1) / 2\n",
    "    # print(out)\n",
    "    return out.clamp(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ab74ef-aaea-417d-bf43-f64d5c72942e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, classes = next(iter(train_loader))\n",
    "inputs = inputs[:6]\n",
    "inputs = [el[0] for el in inputs]\n",
    "classes = classes[:6]\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.imshow(denorm(inputs[i]), cmap='gray', interpolation='none');\n",
    "    plt.title(\"Ground Truth: {}\".format(classes[i]))\n",
    "    # plt.xticks([])\n",
    "    # plt.yticks([])\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211c53d0-cd88-4f8b-9fdd-462fee463f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 784\n",
    "# HIDDEN_SIZE = 256\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8c8251-e11a-4512-bce9-c1fef39142d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.mnist_classifier import train\n",
    "from modules.mnist_models import CNN, CNN2, CNN3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2ee8af-9e39-4326-8d29-48223b698d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "NUM_BATCHES = math.ceil(len(train_loader.dataset)/train_loader.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512696c7-13a3-465c-9631-34e402f4c88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUM_BATCHES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23eb1f9f-63ea-4441-9897-0fa18f5eafe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = CNN3().to(device=device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 0.0001\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "optimizer = torch.optim.Adam(classifier.parameters(), lr=learning_rate)\n",
    "\n",
    "max_lr = 0.0003\n",
    "\n",
    "save_path = '/Users/serafim/Desktop/Job/projects/science/hse/GAN-Estimation-Uncertainty/uncertainty/mnist_tests_classifier'\n",
    "NAME = 'classifier__1_9'\n",
    "\n",
    "scheduler = OneCycleLR(optimizer, max_lr=max_lr, total_steps=NUM_EPOCHS * NUM_BATCHES)\n",
    "\n",
    "# NUM_EPOCHS * len(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d3412f-ec82-4184-b50a-bcd819cf6803",
   "metadata": {},
   "source": [
    "#### OneCycleLR Scheduler Parameters:\n",
    "\n",
    "**max_lr** is the maximum learning rate of OneCycleLR. To be exact, the learning rate will increate from **max_lr** / **div_factor** to **max_lr** in the first **pct_start** * **total_steps** steps, and decrease smoothly to **max_lr** / **final_div_factor** then. div_factor -- Default: 25\n",
    "\n",
    "**final_div_factor** (float) â€“ Determines the minimum learning rate via min_lr = initial_lr/final_div_factor Default: 1e4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f8a9b2-89bd-48ca-969c-8acd550528a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_lr/25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30f88b3-b175-451d-bbdf-e857beaa2183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_loader.dataset)/train_loader.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9a4642-f93e-4073-851b-8ca88589047c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9) # Wrapped optimizer\n",
    "# # scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer,max_lr=0.9,total_steps=EPOCHS * BATCHES)\n",
    "# # NUM_EPOCHS = 10\n",
    "# # learning_rate = 0.0001\n",
    "# # NUM_BATCHES = math.ceil(len(train_loader.dataset)/train_loader.batch_size)\n",
    "# # optimizer = torch.optim.Adam(classifier.parameters(), lr=learning_rate)\n",
    "# # max_lr = 0.0003\n",
    "# # scheduler = OneCycleLR(optimizer, max_lr=max_lr, total_steps=NUM_EPOCHS * NUM_BATCHES)\n",
    "# lrs = []\n",
    "# steps = []\n",
    "# for epoch in range(NUM_EPOCHS):\n",
    "#     for batch in range(NUM_BATCHES):\n",
    "#         scheduler.step()\n",
    "#         lrs.append(scheduler.get_last_lr()[0])\n",
    "#         steps.append(epoch * NUM_BATCHES + batch)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.legend()\n",
    "# plt.plot(steps, lrs, label='OneCycle')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e34ffe3-8bd2-4675-8c12-f5d67da393f2",
   "metadata": {},
   "source": [
    "test cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e2c6a7-37c9-4e63-84d4-df9def559828",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.eval;\n",
    "img = torch.rand(32, 1, 28, 28)  #image 28 on 28 with 1 chanel like in mnist\n",
    "# img, label = train_dataset[0]\n",
    "print(img.size())\n",
    "print('the size of output model to check the output:', classifier(img).size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca95ac8-c9dd-495a-b0f8-ace6b54f803f",
   "metadata": {},
   "source": [
    "test CNNClassifierWrapper to get feature representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd2f307-58d4-4fc9-a7ee-a1aba2f54ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.mnist_models import CNNClassifierWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091af08e-6a64-4d6f-bb51-2a669f460b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_wrapper = CNNClassifierWrapper(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb9813d-02a1-4a68-a359-42ec2888140b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier.eval;\n",
    "img = torch.rand(32, 1, 28, 28)  #image 28 on 28 with 1 chanel like in mnist\n",
    "# img, label = train_dataset[0]\n",
    "print(img.size())\n",
    "# print('the size of output model to check the output:', classifier(img).size())\n",
    "CNN_wrapper.get_nth_layer_result(img).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f764c967-40d3-4ae2-b29c-0b3e82b99463",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1fc6f12f-c015-4fa2-9feb-7363e6c78383",
   "metadata": {},
   "source": [
    "### TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b423619d-daac-40ad-80c0-293c1081c65f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train(\n",
    "    num_epochs = NUM_EPOCHS,\n",
    "    train_loader = train_loader,\n",
    "    test_loader = test_loader,\n",
    "    classifier = classifier,\n",
    "    optimizer = optimizer,\n",
    "    criterion = loss_function,\n",
    "    device = device,\n",
    "    name = NAME, \n",
    "    save_path = save_path,\n",
    "    plot_process = True,\n",
    "    info_n = 2,\n",
    "    scheduler = scheduler,\n",
    "    save_model_name = 'classifier_model.pt'\n",
    "    \n",
    "    # scheduler_D = scheduler_D,\n",
    "    # scheduler_G = scheduler_G\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7bec01-0595-4d3f-a2f2-5b252708ee56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# classifier = CNN2().to(device=device)\n",
    "# loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 0.0001\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "optimizer = torch.optim.Adam(classifier.parameters(), lr=learning_rate)\n",
    "\n",
    "max_lr = 0.001\n",
    "\n",
    "save_path = '/Users/serafim/Desktop/Job/projects/science/hse/GAN-Estimation-Uncertainty/uncertainty/mnist_tests_classifier'\n",
    "NAME = 'classifier__CNN3__1_9_16'\n",
    "\n",
    "scheduler = OneCycleLR(optimizer, max_lr=max_lr, total_steps=NUM_EPOCHS * NUM_BATCHES)\n",
    "\n",
    "# NUM_EPOCHS * len(train_loader)\n",
    "\n",
    "train(\n",
    "    num_epochs = NUM_EPOCHS,\n",
    "    train_loader = train_loader,\n",
    "    test_loader = test_loader,\n",
    "    classifier = classifier,\n",
    "    optimizer = optimizer,\n",
    "    criterion = loss_function,\n",
    "    device = device,\n",
    "    name = NAME, \n",
    "    save_path = save_path,\n",
    "    plot_process = True,\n",
    "    info_n = 2,\n",
    "    scheduler = scheduler,\n",
    "    save_model_name = 'classifier_model.pt'\n",
    "    \n",
    "    # scheduler_D = scheduler_D,\n",
    "    # scheduler_G = scheduler_G\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432b47a5-022f-40a5-9db0-469a1f072755",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# classifier = CNN2().to(device=device)\n",
    "# loss_function = nn.CrossEntropyLoss()\n",
    "for i in range(10):\n",
    "    learning_rate = 0.00003\n",
    "    NUM_EPOCHS = 10\n",
    "\n",
    "    optimizer = torch.optim.Adam(classifier.parameters(), lr=learning_rate)\n",
    "\n",
    "    max_lr = 0.0001\n",
    "\n",
    "    save_path = '/Users/serafim/Desktop/Job/projects/science/hse/GAN-Estimation-Uncertainty/uncertainty/mnist_tests_classifier'\n",
    "    NAME = f'classifier__CNN3__1_9_{i+25}'\n",
    "\n",
    "    scheduler = OneCycleLR(optimizer, max_lr=max_lr, total_steps=NUM_EPOCHS * NUM_BATCHES)\n",
    "\n",
    "    # NUM_EPOCHS * len(train_loader)\n",
    "\n",
    "    train(\n",
    "        num_epochs = NUM_EPOCHS,\n",
    "        train_loader = train_loader,\n",
    "        test_loader = test_loader,\n",
    "        classifier = classifier,\n",
    "        optimizer = optimizer,\n",
    "        criterion = loss_function,\n",
    "        device = device,\n",
    "        name = NAME, \n",
    "        save_path = save_path,\n",
    "        plot_process = True,\n",
    "        info_n = 5,\n",
    "        scheduler = scheduler,\n",
    "        save_model_name = 'classifier_model.pt'\n",
    "\n",
    "        # scheduler_D = scheduler_D,\n",
    "        # scheduler_G = scheduler_G\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047ef45e-9d89-49df-8559-5cb9e9c59dae",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adaf589-293d-4ab0-bbd5-c3949850bcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.mnist_classifier import eval_model, save_model\n",
    "from modules.mnist_models import CNN, CNN2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0160a24-a19a-471c-8a07-3bf17c8ec414",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device=device)\n",
    "# PATH = './mnist_tests_classifier/test/classifier_model.pt'\n",
    "PATH = './mnist_tests_classifier/classifier__1_5/classifier_model.pt'\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42d9f3a-1fc5-4d23-8694-ef395c3e44dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = eval_model(test_loader, classifier, criterion = loss_function, device = device)\n",
    "# a, b = eval_model(test_loader, model, criterion = loss_function, device = device)\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760bebeb-73bc-4715-95bd-e4b763a28118",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from modules.mnist_classifier import get_preds\n",
    "from modules.mnist_classifier import calculate_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f03efb8-6eb7-41f2-8d65-776b11c462a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_confusion_matrix(model, test_loader, device)\n",
    "\n",
    "# y_pred, y_true = get_preds(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfb7a01-d0cf-4ba7-9c2f-3527d5742105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfee32b-92be-46d6-a92b-771a3170ae51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier.eval()\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f61c24b-6777-41de-a09d-6075fc77005f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_model(classifier, save_path = save_path, name = 'test', name2 = 'classifier_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1b58bf-7687-4a32-b7b1-17a55f2019fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
